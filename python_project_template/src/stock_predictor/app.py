"""
·ª®ng d·ª•ng web Streamlit cho H·ªá Th·ªëng D·ª± B√°o Th·ªã Tr∆∞·ªùng Ch·ª©ng Kho√°n
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
import sys
import os
import shutil
import google.generativeai as genai
import time

# Add src to path for imports
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from data.preprocessor import DataPreprocessor
from data.features import add_technical_indicators, FeatureEngineer
# from models.traditional import TraditionalModels  # Commented out for demo

def show_popup_message(message, message_type="success"):
    """Show popup message using streamlit toast for 3 seconds."""
    if message_type == "success":
        st.toast(f"‚úÖ {message}", icon="‚úÖ")
    elif message_type == "error":
        st.toast(f"‚ùå {message}", icon="‚ùå")
    elif message_type == "warning":
        st.toast(f"‚ö†Ô∏è {message}", icon="‚ö†Ô∏è")
    elif message_type == "info":
        st.toast(f"‚ÑπÔ∏è {message}", icon="‚ÑπÔ∏è")
    else:
        st.toast(message)

st.set_page_config(
    page_title="H·ªá Th·ªëng D·ª± B√°o Th·ªã Tr∆∞·ªùng Ch·ª©ng Kho√°n",
    page_icon="üìà",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .section-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #2c3e50;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .metric-container {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def create_sample_data(n_days=3650):  # 10 years of data
    """Create sample stock data for demonstration (2015-2025)."""
    # Use actual date range from 2015 to 2025
    start_date = datetime(2015, 1, 1)
    end_date = datetime(2025, 7, 31)
    dates = pd.date_range(start=start_date, end=end_date, freq='D')
    
    # Use actual number of days in the range
    n_days = len(dates)
    
    # Generate realistic USD/VND-like data (starting around 22,000)
    np.random.seed(42)
    base_price = 22000
    price_changes = np.random.randn(n_days) * 50  # Daily volatility
    close_prices = base_price + np.cumsum(price_changes)
    
    # Ensure prices stay in realistic range
    close_prices = np.clip(close_prices, 20000, 27000)
    
    data = []
    for i, date in enumerate(dates):
        open_price = close_prices[i] + np.random.randn() * 20
        high_price = max(open_price, close_prices[i]) + abs(np.random.randn()) * 30
        low_price = min(open_price, close_prices[i]) - abs(np.random.randn()) * 30
        volume = int(1000000 + np.random.randn() * 100000)
        turnover = volume * close_prices[i]
        
        data.append({
            'code': 'USD_VND',
            'year': date.year,
            'month': date.month,
            'day': date.day,
            'date': date,
            'open': round(open_price, 2),
            'high': round(high_price, 2),
            'low': round(low_price, 2),
            'close': round(close_prices[i], 2),
            'volume': volume,
            'turnover': round(turnover, 2),
            'return': 0.0,
            'target': 0
        })
    
    df = pd.DataFrame(data)
    
    # Calculate return and target
    df['return'] = df['close'].pct_change() * 100
    df['return'] = df['return'].round(2).fillna(0)
    df['target'] = (df['return'] > 0).astype(int)
    
    return df

def plot_price_chart(data):
    """Create price chart with technical indicators using proper date axis."""
    fig = go.Figure()
    
    # Prepare x-axis (dates)
    if 'date' in data.columns:
        x_axis = pd.to_datetime(data['date'])
    else:
        # Create date range from 2015 to 2025 if no date column
        start_date = datetime(2015, 1, 1)
        x_axis = pd.date_range(start=start_date, periods=len(data), freq='D')
    
    # Price line
    fig.add_trace(go.Scatter(
        x=x_axis,
        y=data['close'],
        mode='lines',
        name='Close Price',
        line=dict(color='blue', width=2)
    ))
    
    # Add moving averages - check for different possible column names
    ma_columns = [col for col in data.columns if 'ma_' in col.lower() or 'sma_' in col.lower()]
    
    # Specifically look for MA 5 and MA 20
    ma5_col = None
    ma20_col = None
    
    for col in ma_columns:
        if '5' in col:
            ma5_col = col
        elif '20' in col:
            ma20_col = col
    
    if ma5_col and ma5_col in data.columns and not data[ma5_col].isna().all():
        fig.add_trace(go.Scatter(
            x=x_axis,
            y=data[ma5_col],
            mode='lines',
            name='MA 5',
            line=dict(color='orange', width=1.5)
        ))
    
    if ma20_col and ma20_col in data.columns and not data[ma20_col].isna().all():
        fig.add_trace(go.Scatter(
            x=x_axis,
            y=data[ma20_col],
            mode='lines',
            name='MA 20',
            line=dict(color='red', width=1.5)
        ))
    
    # Add Bollinger Bands if available
    bb_columns = [col for col in data.columns if 'bb_' in col.lower()]
    bb_upper = None
    bb_lower = None
    bb_middle = None
    
    for col in bb_columns:
        if 'upper' in col.lower() or 'bbh' in col.lower():
            bb_upper = col
        elif 'lower' in col.lower() or 'bbl' in col.lower():
            bb_lower = col
        elif 'middle' in col.lower() or 'bbm' in col.lower():
            bb_middle = col
    
    if bb_upper and bb_lower and bb_upper in data.columns and bb_lower in data.columns:
        if not data[bb_upper].isna().all() and not data[bb_lower].isna().all():
            fig.add_trace(go.Scatter(
                x=x_axis,
                y=data[bb_upper],
                mode='lines',
                name='BB Upper',
                line=dict(color='gray', width=1, dash='dot'),
                showlegend=False
            ))
            fig.add_trace(go.Scatter(
                x=x_axis,
                y=data[bb_lower],
                mode='lines',
                name='BB Lower',
                line=dict(color='gray', width=1, dash='dot'),
                fill='tonexty',
                fillcolor='rgba(128,128,128,0.1)',
                showlegend=False
            ))
    
    fig.update_layout(
        title='Ch·ªâ S·ªë VN30 v·ªõi C√°c Ch·ªâ B√°o K·ªπ Thu·∫≠t',
        xaxis_title='Ng√†y',
        yaxis_title='Gi√°',
        height=500,
        showlegend=True
    )
    
    return fig

def plot_technical_indicators(data):
    """Plot technical indicators with proper date axis."""
    fig = go.Figure()
    
    # Prepare x-axis (dates)
    if 'date' in data.columns:
        x_axis = pd.to_datetime(data['date'])
    else:
        # Create date range from 2015 to 2025 if no date column
        start_date = datetime(2015, 1, 1)
        x_axis = pd.date_range(start=start_date, periods=len(data), freq='D')
    
    # Look for RSI columns
    rsi_columns = [col for col in data.columns if 'rsi' in col.lower()]
    
    if rsi_columns:
        rsi_col = rsi_columns[0]  # Use the first RSI column found
        if not data[rsi_col].isna().all():
            fig.add_trace(go.Scatter(
                x=x_axis,
                y=data[rsi_col],
                mode='lines',
                name=f'RSI ({rsi_col})',
                line=dict(color='purple', width=2)
            ))
            
            # Add RSI levels
            fig.add_hline(y=70, line_dash="dash", line_color="red", annotation_text="Mua qu√° m·ª©c (70)")
            fig.add_hline(y=30, line_dash="dash", line_color="green", annotation_text="B√°n qu√° m·ª©c (30)")
            
            fig.update_layout(
                title='Ch·ªâ B√°o K·ªπ Thu·∫≠t RSI',
                xaxis_title='Ng√†y',
                yaxis_title='Gi√° Tr·ªã RSI',
                height=300,
                yaxis=dict(range=[0, 100])
            )
        else:
            # No valid RSI data
            fig.add_annotation(
                text="Kh√¥ng c√≥ d·ªØ li·ªáu RSI",
                xref="paper", yref="paper",
                x=0.5, y=0.5, showarrow=False
            )
            fig.update_layout(
                title='Ch·ªâ B√°o K·ªπ Thu·∫≠t RSI (Kh√¥ng c√≥ d·ªØ li·ªáu)',
                xaxis_title='Ng√†y',
                yaxis_title='Gi√° Tr·ªã RSI',
                height=300
            )
    else:
        # No RSI columns found
        fig.add_annotation(
            text="Kh√¥ng t√¨m th·∫•y ch·ªâ b√°o RSI",
            xref="paper", yref="paper",
            x=0.5, y=0.5, showarrow=False
        )
        fig.update_layout(
            title='Ch·ªâ B√°o K·ªπ Thu·∫≠t RSI (Kh√¥ng c√≥ s·∫µn)',
            xaxis_title='Ng√†y',
            yaxis_title='Gi√° Tr·ªã RSI',
            height=300
        )
    
    return fig

def generate_future_prediction(data_summary):
    """Generate a future prediction based on historical data trends."""
    current_price = data_summary['current_price']
    avg_volatility = data_summary['avg_volatility']
    up_days_ratio = data_summary['up_days_ratio']
    
    # Simple trend analysis
    if up_days_ratio > 52:
        trend = "tƒÉng tr∆∞·ªüng"
        direction = "üìà"
        growth_estimate = "2-5%"
    elif up_days_ratio < 48:
        trend = "gi·∫£m"
        direction = "üìâ"
        growth_estimate = "-2 ƒë·∫øn -5%"
    else:
        trend = "·ªïn ƒë·ªãnh"
        direction = "‚û°Ô∏è"
        growth_estimate = "-1 ƒë·∫øn +1%"
    
    # Generate 10-year projection
    projection_text = f"""
    **D·ª± b√°o m·ªü r·ªông cho 10 nƒÉm ti·∫øp theo (2025-2035):**
    
    {direction} **Xu h∆∞·ªõng d√†i h·∫°n:** {trend}
    
    üìä **∆Ø·ªõc t√≠nh tƒÉng tr∆∞·ªüng h√†ng nƒÉm:** {growth_estimate}
    
    üéØ **K·ªãch b·∫£n d·ª± ki·∫øn:**
    - **NƒÉm 1-3 (2025-2027):** Ti·∫øp t·ª•c xu h∆∞·ªõng hi·ªán t·∫°i v·ªõi bi·∫øn ƒë·ªông {avg_volatility:.1f}%
    - **NƒÉm 4-7 (2028-2031):** ƒêi·ªÅu ch·ªânh theo chu k·ª≥ kinh t·∫ø
    - **NƒÉm 8-10 (2032-2035):** ·ªîn ƒë·ªãnh ·ªü m·ª©c gi√° m·ªõi
    
    üí° **L∆∞u √Ω:** D·ª± b√°o d√†i h·∫°n c√≥ ƒë·ªô kh√¥ng ch·∫Øc ch·∫Øn cao do nhi·ªÅu y·∫øu t·ªë kh√¥ng d·ª± ƒëo√°n ƒë∆∞·ª£c.
    """
    
    return projection_text

def calculate_time_duration(data):
    """Calculate the time duration of the dataset."""
    if 'date' in data.columns:
        dates = pd.to_datetime(data['date'])
        start_date = dates.min()
        end_date = dates.max()
        duration = end_date - start_date
        years = duration.days / 365.25
        return f"{years:.1f} nƒÉm ({start_date.strftime('%Y-%m-%d')} ƒë·∫øn {end_date.strftime('%Y-%m-%d')})"
    else:
        # Fallback: estimate from row count
        years = len(data) / 365.25
        return f"~{years:.1f} nƒÉm ({len(data)} ƒëi·ªÉm d·ªØ li·ªáu)"

def get_gemini_prediction(data_summary, api_key):
    """Get AI-based market prediction using Gemini Pro."""
    try:
        # Configure Gemini
        genai.configure(api_key=api_key)
        
        # Use the latest Gemini model
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        # Create prompt for stock market analysis
        prompt = f"""
        Ph√¢n t√≠ch d·ªØ li·ªáu th·ªã tr∆∞·ªùng ch·ª©ng kho√°n sau v√† ƒë∆∞a ra d·ª± b√°o:

        Th√¥ng tin d·ªØ li·ªáu:
        - T·ªïng s·ªë ng√†y giao d·ªãch: {data_summary['total_days']}
        - Kho·∫£ng th·ªùi gian: {data_summary['time_duration']}
        - Gi√° ƒë√≥ng c·ª≠a hi·ªán t·∫°i: {data_summary['current_price']:.2f}
        - Thay ƒë·ªïi gi√° g·∫ßn nh·∫•t: {data_summary['latest_change']:.2f}%
        - T·ª∑ l·ªá ng√†y tƒÉng gi√°: {data_summary['up_days_ratio']:.1f}%
        - Gi√° cao nh·∫•t: {data_summary['highest_price']:.2f}
        - Gi√° th·∫•p nh·∫•t: {data_summary['lowest_price']:.2f}
        - Bi·∫øn ƒë·ªông trung b√¨nh: {data_summary['avg_volatility']:.2f}%

        H√£y ph√¢n t√≠ch xu h∆∞·ªõng v√† ƒë∆∞a ra:
        1. ƒê√°nh gi√° t√¨nh h√¨nh th·ªã tr∆∞·ªùng hi·ªán t·∫°i
        2. D·ª± b√°o xu h∆∞·ªõng ng·∫Øn h·∫°n (1-2 tu·∫ßn)
        3. D·ª± b√°o xu h∆∞·ªõng trung h·∫°n (1-3 th√°ng)
        4. C√°c y·∫øu t·ªë r·ªßi ro c·∫ßn l∆∞u √Ω
        5. Khuy·∫øn ngh·ªã ƒë·∫ßu t∆∞ (n·∫øu c√≥)

        Vui l√≤ng tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát v√† cung c·∫•p ph√¢n t√≠ch chi ti·∫øt, kh√°ch quan.
        """
        
        # Generate response
        response = model.generate_content(prompt)
        return response.text
        
    except Exception as e:
        return f"L·ªói khi g·ªçi Gemini API: {str(e)}"

def format_gemini_response(response_text):
    """Format Gemini response for better display."""
    # Split into sections
    sections = response_text.split('\n\n')
    
    formatted_sections = []
    for section in sections:
        if section.strip():
            # Check if it's a header (starts with number)
            if section.strip().startswith(('1.', '2.', '3.', '4.', '5.')):
                formatted_sections.append(f"**{section.strip()}**")
            else:
                formatted_sections.append(section.strip())
    
    return '\n\n'.join(formatted_sections)

def main():
    """Main application function."""
    
    # Header
    st.markdown('<div class="main-header">üìà H·ªá Th·ªëng D·ª± B√°o Th·ªã Tr∆∞·ªùng</div>', unsafe_allow_html=True)
    st.markdown('<div style="text-align: center; margin-bottom: 2rem;">D·ª± b√°o ch·ªâ s·ªë th·ªã tr∆∞·ªùng s·ª≠ d·ª•ng Machine Learning v√† AI</div>', unsafe_allow_html=True)
    
    # Sidebar
    st.sidebar.header("‚öôÔ∏è H·ªá Th·ªëng Ch√≠nh")
    
    # Demo options - define this first
    demo_option = st.sidebar.selectbox(
        "Ch·ªçn Ki·ªÉu Demo",
        ["Demo D·ªØ Li·ªáu M·∫´u", "T·∫£i File CSV", "Demo D·ª± B√°o"]
    )
    
    # AI Prediction Button - only show if we have data
    st.sidebar.markdown("### ü§ñ D·ª± B√°o AI")
    
    # Check if we have any data available for AI prediction
    has_sample_data = demo_option == "Demo D·ªØ Li·ªáu M·∫´u"
    
    # For Upload CSV, check if process button was clicked or data already exists
    has_uploaded_data = False
    if demo_option == "T·∫£i File CSV":
        # Check if data is already processed
        data_processed = st.session_state.get('upload_processed', False)
        data_exists = 'uploaded_data' in st.session_state
        
        has_uploaded_data = data_processed and data_exists
    
    if has_sample_data or has_uploaded_data:
        use_ai_prediction = st.sidebar.button(
            "üß† Nh·∫≠n D·ª± B√°o Th·ªã Tr∆∞·ªùng AI",
            type="primary",
            help="Nh·∫•p ƒë·ªÉ nh·∫≠n ph√¢n t√≠ch v√† d·ª± b√°o th·ªã tr∆∞·ªùng b·∫±ng AI",
            use_container_width=True
        )
    else:
        use_ai_prediction = False
        if demo_option == "T·∫£i File CSV":
            if not st.session_state.get('upload_processed', False):
                st.sidebar.info("üí° Vui l√≤ng t·∫£i l√™n v√† x·ª≠ l√Ω file CSV tr∆∞·ªõc")
            else:
                st.sidebar.warning("‚ö†Ô∏è D·ªØ li·ªáu kh√¥ng s·∫µn s√†ng cho d·ª± b√°o AI")
        else:
            st.sidebar.info("üí° Ch·ªçn demo ho·∫∑c t·∫£i d·ªØ li·ªáu ƒë·ªÉ s·ª≠ d·ª•ng d·ª± b√°o AI")
    
    
    if demo_option == "Demo D·ªØ Li·ªáu M·∫´u":
        st.markdown('<div class="section-header">üìä Ph√¢n T√≠ch D·ªØ Li·ªáu M·∫´u</div>', unsafe_allow_html=True)
        
        # Load real VN30 data instead of synthetic data
        vn30_file_path = "/Users/dungnhi/Documents/HTRaQuyetDinh/VN30_demo.csv"
        
        try:
            with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu VN30..."):
                # Load and process VN30 data using DataPreprocessor
                preprocessor = DataPreprocessor()
                vn30_data = preprocessor._read_csv_flexible(vn30_file_path)
                
                if vn30_data is None:
                    raise Exception("Kh√¥ng th·ªÉ ƒë·ªçc file CSV VN30")
                
                # Process the VN30 data directly
                vn30_data = preprocessor._normalize_data_format(vn30_data, "VN30")
                
                if vn30_data is None or vn30_data.empty:
                    raise Exception("Kh√¥ng th·ªÉ chu·∫©n h√≥a ƒë·ªãnh d·∫°ng d·ªØ li·ªáu VN30")
                
                # Calculate returns and targets
                vn30_data = preprocessor._calculate_returns_and_targets(vn30_data)
                
                # Use this as our sample data
                sample_data = vn30_data.copy()
                
            show_popup_message("ƒê√£ t·∫£i th√†nh c√¥ng d·ªØ li·ªáu VN30!", "success")
            
            # Show actual VN30 data analysis
            with st.expander("üìä Ph√¢n T√≠ch D·ªØ Li·ªáu VN30", expanded=True):
                st.write("**Ngu·ªìn D·ªØ Li·ªáu:** D·ªØ Li·ªáu L·ªãch S·ª≠ Ch·ªâ S·ªë VN30 Vi·ªát Nam")
                
                # Show raw data sample
                st.write("**D·ªØ Li·ªáu VN30 Th√¥ (10 d√≤ng ƒë·∫ßu):**")
                display_data = sample_data.head(10).copy()
                if 'date' in display_data.columns:
                    display_data['date'] = pd.to_datetime(display_data['date']).dt.strftime('%Y-%m-%d')
                st.dataframe(display_data, use_container_width=True)
            
            show_popup_message("ƒêang s·ª≠ d·ª•ng d·ªØ li·ªáu ch·ªâ s·ªë VN30 th·ª±c t·∫ø", "info")
            
        except Exception as e:
            show_popup_message(f"Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu VN30: {str(e)}. S·ª≠ d·ª•ng d·ªØ li·ªáu t·ªïng h·ª£p thay th·∫ø.", "warning")
            # Fallback to synthetic data
            with st.spinner("ƒêang t·∫°o d·ªØ li·ªáu m·∫´u..."):
                sample_data = create_sample_data()
        
        # Calculate time duration
        time_duration = calculate_time_duration(sample_data)
        
        # Display basic info
        col1, col2, col3, col4, col5 = st.columns(5)
        with col1:
            st.metric("Th·ªùi Gian", time_duration.split(' (')[0])  # Just the years part
        with col2:
            st.metric("T·ªïng S·ªë Ng√†y", len(sample_data))
        with col3:
            st.metric("Gi√° M·ªõi Nh·∫•t", f"{sample_data['close'].iloc[-1]:.2f}")
        with col4:
            if 'return' in sample_data.columns:
                st.metric("Thay ƒê·ªïi Gi√° %", f"{sample_data['return'].iloc[-1]:.2f}%")
            else:
                st.metric("Thay ƒê·ªïi Gi√° %", "N/A")
        with col5:
            if 'target' in sample_data.columns:
                up_days = (sample_data['target'] == 1).sum()
                st.metric("% Ng√†y TƒÉng", f"{100 * up_days / len(sample_data):.1f}%")
            else:
                st.metric("% Ng√†y TƒÉng", "N/A")
        
        # Add technical indicators
        st.markdown('<div class="section-header">üîß K·ªπ Thu·∫≠t X√¢y D·ª±ng ƒê·∫∑c Tr∆∞ng</div>', unsafe_allow_html=True)
        
        with st.spinner("ƒêang th√™m c√°c ch·ªâ b√°o k·ªπ thu·∫≠t..."):
            data_with_features = add_technical_indicators(sample_data)
        
        show_popup_message("ƒê√£ th√™m th√†nh c√¥ng c√°c ch·ªâ b√°o k·ªπ thu·∫≠t!", "success")
        
        # Debug: Show what indicators were actually added
        with st.expander("üîç G·ª° L·ªói: Tr·∫°ng Th√°i Ch·ªâ B√°o K·ªπ Thu·∫≠t"):
            st.write("**C√°c c·ªôt c√≥ s·∫µn sau khi th√™m ch·ªâ b√°o k·ªπ thu·∫≠t:**")
            all_cols = list(data_with_features.columns)
            original_cols = list(sample_data.columns)
            new_cols = [col for col in all_cols if col not in original_cols]
            
            st.write(f"C·ªôt g·ªëc ({len(original_cols)}): {original_cols}")
            st.write(f"Ch·ªâ b√°o k·ªπ thu·∫≠t m·ªõi ({len(new_cols)}): {new_cols}")
            
            # Check for specific MA indicators
            ma_indicators = [col for col in new_cols if 'ma_' in col.lower()]
            rsi_indicators = [col for col in new_cols if 'rsi' in col.lower()]
            bb_indicators = [col for col in new_cols if 'bb_' in col.lower()]
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.write(f"**Ch·ªâ B√°o MA:** {ma_indicators}")
            with col2:
                st.write(f"**Ch·ªâ B√°o RSI:** {rsi_indicators}")
            with col3:
                st.write(f"**D·∫£i Bollinger:** {bb_indicators}")
            
            # Show sample of technical indicator values
            if len(new_cols) > 0:
                st.write("**Gi√° tr·ªã m·∫´u (5 d√≤ng cu·ªëi):**")
                sample_tech = data_with_features[new_cols].tail()
                st.dataframe(sample_tech, use_container_width=True)
        
        # Show feature columns
        with st.expander("Xem C√°c Ch·ªâ B√°o K·ªπ Thu·∫≠t"):
            new_features = set(data_with_features.columns) - set(sample_data.columns)
            st.write("**Ch·ªâ b√°o k·ªπ thu·∫≠t m·ªõi ƒë∆∞·ª£c th√™m:**")
            for feature in sorted(new_features):
                st.write(f"‚Ä¢ {feature}")
        
        # Visualizations
        st.markdown('<div class="section-header">üìà Bi·ªÉu ƒê·ªì & Ph√¢n T√≠ch</div>', unsafe_allow_html=True)
        
        # Price chart
        st.write("**Bi·ªÉu ƒê·ªì Gi√° Ch·ªâ S·ªë VN30 v·ªõi C√°c Ch·ªâ B√°o K·ªπ Thu·∫≠t:**")
        price_fig = plot_price_chart(data_with_features)
        st.plotly_chart(price_fig, use_container_width=True)
        
        # Show chart info
        with st.expander("üìä Th√¥ng Tin Bi·ªÉu ƒê·ªì"):
            available_indicators = []
            ma_cols = [col for col in data_with_features.columns if 'ma_' in col.lower() or 'sma_' in col.lower()]
            bb_cols = [col for col in data_with_features.columns if 'bb_' in col.lower()]
            rsi_cols = [col for col in data_with_features.columns if 'rsi' in col.lower()]
            
            if ma_cols:
                available_indicators.append(f"ƒê∆∞·ªùng Trung B√¨nh ƒê·ªông: {ma_cols}")
            if bb_cols:
                available_indicators.append(f"D·∫£i Bollinger: {bb_cols}")
            if rsi_cols:
                available_indicators.append(f"RSI: {rsi_cols}")
            
            if available_indicators:
                st.write("**Ch·ªâ b√°o k·ªπ thu·∫≠t hi·ªÉn th·ªã:**")
                for indicator in available_indicators:
                    st.write(f"‚Ä¢ {indicator}")
            else:
                st.warning("Kh√¥ng t√¨m th·∫•y ch·ªâ b√°o k·ªπ thu·∫≠t trong d·ªØ li·ªáu")
        
        # Technical indicators chart
        st.write("**Ch·ªâ B√°o K·ªπ Thu·∫≠t RSI:**")
        rsi_fig = plot_technical_indicators(data_with_features)
        st.plotly_chart(rsi_fig, use_container_width=True)
        
        # Feature engineering demo
        st.markdown('<div class="section-header">üß† K·ªπ Thu·∫≠t X√¢y D·ª±ng ƒê·∫∑c Tr∆∞ng N√¢ng Cao</div>', unsafe_allow_html=True)
        
        feature_engineer = FeatureEngineer()
        
        with st.spinner("ƒêang t·∫°o c√°c ƒë·∫∑c tr∆∞ng b·ªï sung..."):
            # Add more features using the real VN30 data
            enriched_data = feature_engineer.create_price_features(data_with_features)
            enriched_data = feature_engineer.create_volume_features(enriched_data)
            enriched_data = feature_engineer.create_lag_features(enriched_data)
            enriched_data = feature_engineer.create_rolling_features(enriched_data)
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ƒê·∫∑c Tr∆∞ng G·ªëc", len(sample_data.columns))
        with col2:
            st.metric("ƒê·∫∑c Tr∆∞ng Cu·ªëi C√πng", len(enriched_data.columns))
        
        # Show data sample
        st.markdown('<div class="section-header">üìã Xem Tr∆∞·ªõc D·ªØ Li·ªáu</div>', unsafe_allow_html=True)
        
        st.write("**Xem tr∆∞·ªõc b·ªô d·ªØ li·ªáu cu·ªëi c√πng (D·ªØ Li·ªáu VN30 Th·ª±c T·∫ø):**")
        st.dataframe(enriched_data.head(), use_container_width=True)
        
        # Additional info about the VN30 data
        with st.expander("‚ÑπÔ∏è V·ªÅ D·ªØ Li·ªáu VN30"):
            st.write("**Ngu·ªìn D·ªØ Li·ªáu:** D·ªØ Li·ªáu L·ªãch S·ª≠ Ch·ªâ S·ªë VN30 Vi·ªát Nam")
            st.write("**S·ªë B·∫£n Ghi:**", len(sample_data))
            st.write("**ƒê·∫∑c tr∆∞ng sau khi enrich data:**", len(enriched_data.columns))
        
        # Model demonstration
        st.markdown('<div class="section-header">ü§ñ Demo Hu·∫•n Luy·ªán M√¥ H√¨nh</div>', unsafe_allow_html=True)
        
        if st.button("üöÄ Ch·∫°y Demo Hu·∫•n Luy·ªán M√¥ H√¨nh", type="primary"):
            with st.spinner("ƒêang chu·∫©n b·ªã d·ªØ li·ªáu cho m√¥ h√¨nh..."):
                # Prepare data for modeling
                # Show data info before cleaning
                st.info(f"üìä D·ªØ li·ªáu tr∆∞·ªõc khi l√†m s·∫°ch: {enriched_data.shape}")
                st.info(f"üìä Gi√° tr·ªã NaN: {enriched_data.isnull().sum().sum()}")
                
                # Remove rows with NaN values, but be more flexible
                clean_data = enriched_data.dropna()
                
                st.info(f"üìä D·ªØ li·ªáu sau khi l√†m s·∫°ch: {clean_data.shape}")
                
                # Lower the threshold for minimum data points
                min_required_samples = min(20, len(enriched_data) // 4)  # More flexible threshold
                
                if len(clean_data) >= min_required_samples:  # Ensure we have enough data
                    # Split features and target
                    feature_cols = [col for col in clean_data.columns if col not in ['code', 'target', 'date', 'year', 'month', 'day']]
                    
                    # Select only numeric columns for modeling
                    numeric_features = []
                    for col in feature_cols:
                        if pd.api.types.is_numeric_dtype(clean_data[col]):
                            numeric_features.append(col)
                    
                    X = clean_data[numeric_features]
                    y = clean_data['target']
                    
                    st.info(f"üìä ƒê√£ ch·ªçn {len(numeric_features)} ƒë·∫∑c tr∆∞ng s·ªë cho m√¥ h√¨nh")
                    
                    # Simple train/test split
                    split_idx = max(1, int(0.8 * len(clean_data)))  # Ensure at least 1 sample for test
                    X_train, X_test = X[:split_idx], X[split_idx:]
                    y_train, y_test = y[:split_idx], y[split_idx:]
                    
                    show_popup_message(f"D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chu·∫©n b·ªã: {len(X_train)} m·∫´u hu·∫•n luy·ªán, {len(X_test)} m·∫´u ki·ªÉm tra", "success")
                    
                    # Show feature importance simulation
                    np.random.seed(42)
                    feature_importance = np.random.rand(min(10, len(numeric_features)))
                    top_features = np.array(numeric_features[:len(feature_importance)])
                    
                    importance_df = pd.DataFrame({
                        'Feature': top_features,
                        'Importance': feature_importance
                    }).sort_values('Importance', ascending=True)
                    
                    fig_importance = px.bar(
                        importance_df,
                        x='Importance',
                        y='Feature',
                        orientation='h',
                        title='M·ª©c ƒê·ªô Quan Tr·ªçng ƒê·∫∑c Tr∆∞ng M√¥ Ph·ªèng'
                    )
                    st.plotly_chart(fig_importance, use_container_width=True)
                    
                    # Simulated model results
                    st.write("**Hi·ªáu Su·∫•t M√¥ H√¨nh M√¥ Ph·ªèng:**")
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ƒê·ªô Ch√≠nh X√°c", "75.2%")
                    with col2:
                        st.metric("ƒê·ªô Ch√≠nh X√°c", "73.8%")
                    with col3:
                        st.metric("ƒê·ªô Nh·∫°y", "76.5%")
                    
                else:
                    st.error(f"Kh√¥ng ƒë·ªß d·ªØ li·ªáu s·∫°ch ƒë·ªÉ m√¥ h√¨nh h√≥a. C·∫ßn √≠t nh·∫•t {min_required_samples} m·∫´u, nh∆∞ng ch·ªâ c√≥ {len(clean_data)} sau khi l√†m s·∫°ch.")
                    st.error("H√£y th·ª≠ t·∫£i l√™n nhi·ªÅu d·ªØ li·ªáu h∆°n ho·∫∑c ki·ªÉm tra ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu.")
        
        # AI Prediction Section
        st.markdown('<div class="section-header">ü§ñ D·ª± B√°o Th·ªã Tr∆∞·ªùng D·ª±a Tr√™n AI</div>', unsafe_allow_html=True)
        
        if use_ai_prediction:
            with st.spinner("ƒêang ph√¢n t√≠ch d·ªØ li·ªáu v·ªõi AI..."):
                # Prepare data summary for AI analysis
                data_summary = {
                    'total_days': len(enriched_data),
                    'time_duration': time_duration,
                    'current_price': sample_data['close'].iloc[-1],
                    'latest_change': sample_data['return'].iloc[-1],
                    'up_days_ratio': 100 * (sample_data['target'] == 1).sum() / len(sample_data),
                    'highest_price': sample_data['close'].max(),
                    'lowest_price': sample_data['close'].min(),
                    'avg_volatility': abs(sample_data['return']).mean()
                }
                api_key = "AIzaSyDMs-iLWgB7NuoCtJLqEj4SwG3qhM3B-gQ"
                ai_prediction = get_gemini_prediction(data_summary, api_key)
                st.markdown("---")
                st.markdown("### üîÆ AI Market Analysis & Prediction")
                if "L·ªói" not in ai_prediction:
                    with st.expander("üìä Xem d·ª± b√°o AI cho 10 nƒÉm ti·∫øp theo", expanded=True):
                        st.success("‚úÖ AI ƒë√£ ph√¢n t√≠ch xong!")
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("S·ªë ng√†y ph√¢n t√≠ch", f"{data_summary['total_days']:,}")
                        with col2:
                            st.metric("Gi√° hi·ªán t·∫°i", f"{data_summary['current_price']:.2f}")
                        with col3:
                            st.metric("Thay ƒë·ªïi g·∫ßn nh·∫•t", f"{data_summary['latest_change']:.2f}%")
                        with col4:
                            st.metric("T·ª∑ l·ªá ng√†y tƒÉng", f"{data_summary['up_days_ratio']:.1f}%")
                        st.markdown("---")
                        st.markdown("#### ÔøΩ D·ª± b√°o chi ti·∫øt:")
                        formatted_response = format_gemini_response(ai_prediction)
                        st.markdown(
                            f"""
                            <div style='background-color: #000000; color: #ffffff; padding: 20px; border-radius: 10px; border-left: 5px solid #1f77b4; margin: 10px 0;'>
                                {formatted_response}
                            </div>
                            """,
                            unsafe_allow_html=True
                        )
                        st.markdown("#### üîÆ D·ª± b√°o m·ªü r·ªông (10 nƒÉm ti·∫øp theo)")
                        future_prediction = generate_future_prediction(data_summary)
                        st.info(future_prediction)
                        st.markdown("---")
                        st.warning(
                            "‚ö†Ô∏è **L∆ØU √ù QUAN TR·ªåNG:** ƒê√¢y l√† ph√¢n t√≠ch AI d·ª±a tr√™n d·ªØ li·ªáu l·ªãch s·ª≠. "
                            "Kh√¥ng ƒë∆∞·ª£c coi l√† l·ªùi khuy√™n ƒë·∫ßu t∆∞. Th·ªã tr∆∞·ªùng ch·ª©ng kho√°n c√≥ r·ªßi ro cao. "
                            "Vui l√≤ng tham kh·∫£o √Ω ki·∫øn chuy√™n gia t√†i ch√≠nh tr∆∞·ªõc khi ƒë∆∞a ra quy·∫øt ƒë·ªãnh ƒë·∫ßu t∆∞."
                        )
                else:
                    st.error(ai_prediction)
        else:
            st.info("üí° Nh·∫•p v√†o n√∫t 'Nh·∫≠n D·ª± B√°o Th·ªã Tr∆∞·ªùng AI' trong thanh b√™n ƒë·ªÉ nh·∫≠n ph√¢n t√≠ch AI v·ªÅ th·ªã tr∆∞·ªùng")
    
    elif demo_option == "Demo D·ª± B√°o":
        # Import forecaster here to avoid circular imports
        from forecast.forecaster import StockForecaster
        
        st.markdown('<div class="section-header">üìà Demo D·ª± B√°o Gi√°</div>', unsafe_allow_html=True)
        
        # Initialize forecaster
        forecaster = StockForecaster()
        
        # Load forecast data
        with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu d·ª± b√°o..."):
            data_loaded = forecaster.load_forecast_data()
        
        if not data_loaded:
            show_popup_message("Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu d·ª± b√°o. Vui l√≤ng ki·ªÉm tra c√°c file d·ªØ li·ªáu.", "error")
            st.error("‚ùå Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu d·ª± b√°o t·ª´ Desktop")
            st.error("Vui l√≤ng ƒë·∫£m b·∫£o c√°c file sau t·ªìn t·∫°i tr√™n Desktop:")
            st.write("- D·ªØ li·ªáu L·ªãch s·ª≠ USD_VND.csv")
            st.write("- d·ªØ li·ªáu l·ªãch s·ª≠ gi√° v√†ng.csv")
            return
        
        show_popup_message(f"ƒê√£ t·∫£i {len(forecaster.available_symbols)} b·ªô d·ªØ li·ªáu d·ª± b√°o", "success")
        
        # Symbol selection
        selected_symbol = st.selectbox(
            "Ch·ªçn ch·ªâ s·ªë ƒë·ªÉ d·ª± b√°o:",
            forecaster.available_symbols,
            help="Ch·ªçn USD/VND ho·∫∑c Gold ƒë·ªÉ xem d·ª± b√°o"
        )
        
        # Forecast days selection
        forecast_days = st.slider(
            "S·ªë ng√†y d·ª± b√°o:",
            min_value=7,
            max_value=90,
            value=30,
            help="Ch·ªçn s·ªë ng√†y b·∫°n mu·ªën d·ª± b√°o v√†o t∆∞∆°ng lai"
        )
        
        if st.button("üîÆ T·∫°o D·ª± B√°o", type="primary"):
            with st.spinner(f"ƒêang t·∫°o d·ª± b√°o cho {selected_symbol}..."):
                # Create forecast chart
                forecast_chart = forecaster.create_forecast_chart(
                    selected_symbol, 
                    forecast_days=forecast_days,
                    historical_days=90
                )
                
                if forecast_chart is None:
                    show_popup_message("Kh√¥ng th·ªÉ t·∫°o d·ª± b√°o. Vui l√≤ng th·ª≠ l·∫°i.", "error")
                    return
                
                # Display chart
                st.plotly_chart(forecast_chart, use_container_width=True)
                
                # Get forecast summary
                summary = forecaster.get_forecast_summary(selected_symbol, forecast_days)
                
                if summary:
                    # Display forecast summary
                    st.markdown("### üìä T√≥m T·∫Øt D·ª± B√°o")
                    
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("Gi√° Hi·ªán T·∫°i", f"{summary['current_price']:,.0f}")
                    with col2:
                        st.metric("Gi√° D·ª± B√°o", f"{summary['forecast_end_price']:,.0f}")
                    with col3:
                        st.metric("Thay ƒê·ªïi", f"{summary['price_change']:,.0f}")
                    with col4:
                        st.metric("Thay ƒê·ªïi %", f"{summary['price_change_pct']:.1f}%")
                    
                    # Investment recommendation
                    st.markdown("### üí∞ Khuy·∫øn Ngh·ªã ƒê·∫ßu T∆∞")
                    
                    # Create colored background based on trend
                    if summary['trend_color'] == 'green':
                        bg_color = "#d4edda"
                        text_color = "#155724"
                        border_color = "#c3e6cb"
                    elif summary['trend_color'] == 'lightgreen':
                        bg_color = "#d1ecf1"
                        text_color = "#0c5460"
                        border_color = "#bee5eb"
                    elif summary['trend_color'] == 'orange':
                        bg_color = "#fff3cd"
                        text_color = "#856404"
                        border_color = "#ffeaa7"
                    else:  # red
                        bg_color = "#f8d7da"
                        text_color = "#721c24"
                        border_color = "#f5c6cb"
                    
                    st.markdown(
                        f"""
                        <div style="
                            background-color: {bg_color}; 
                            color: {text_color}; 
                            padding: 15px; 
                            border-radius: 10px; 
                            border-left: 5px solid {border_color};
                            margin: 10px 0;
                        ">
                            <h4 style="margin: 0; color: {text_color};">Xu H∆∞·ªõng: {summary['trend']}</h4>
                            <p style="margin: 5px 0; color: {text_color};">
                                <strong>Bi·∫øn ƒë·ªông l·ªãch s·ª≠:</strong> {summary['historical_volatility']:.2f}%<br>
                                <strong>Gi√° cao nh·∫•t d·ª± ki·∫øn:</strong> {summary['max_forecast_price']:,.0f}<br>
                                <strong>Gi√° th·∫•p nh·∫•t d·ª± ki·∫øn:</strong> {summary['min_forecast_price']:,.0f}<br>
                                <strong>Gi√° trung b√¨nh d·ª± ki·∫øn:</strong> {summary['avg_forecast_price']:,.0f}
                            </p>
                        </div>
                        """,
                        unsafe_allow_html=True
                    )
                    
                    # Risk assessment
                    st.markdown("### ‚ö†Ô∏è ƒê√°nh Gi√° R·ªßi Ro")
                    if summary['historical_volatility'] > 5:
                        risk_level = "Cao"
                        risk_color = "#dc3545"  # Red
                        risk_bg_color = "#f8d7da"  # Light red background
                        risk_border_color = "#f5c6cb"  # Red border
                    elif summary['historical_volatility'] > 2:
                        risk_level = "Trung B√¨nh"
                        risk_color = "#fd7e14"  # Orange
                        risk_bg_color = "#fff3cd"  # Light orange background
                        risk_border_color = "#ffeaa7"  # Orange border
                    else:
                        risk_level = "Th·∫•p"
                        risk_color = "#28a745"  # Green
                        risk_bg_color = "#d4edda"  # Light green background
                        risk_border_color = "#c3e6cb"  # Green border
                    
                    st.markdown(
                        f"""
                        <div style="
                            background-color: {risk_bg_color}; 
                            color: #495057; 
                            padding: 15px; 
                            border-radius: 10px; 
                            border: 2px solid {risk_border_color};
                            margin: 10px 0;
                        ">
                            <p style="margin: 0;"><strong>M·ª©c ƒë·ªô r·ªßi ro:</strong> <span style="color: {risk_color}; font-weight: bold; font-size: 1.1em;">{risk_level}</span></p>
                            <p style="margin: 10px 0 0 0; font-size: 0.9em;"><strong>Bi·∫øn ƒë·ªông l·ªãch s·ª≠:</strong> {summary['historical_volatility']:.2f}%</p>
                            <p style="margin: 10px 0 0 0; font-size: 0.9em;"><strong>L∆∞u √Ω:</strong> D·ª± b√°o d·ª±a tr√™n d·ªØ li·ªáu l·ªãch s·ª≠ v√† m√¥ h√¨nh to√°n h·ªçc. 
                            K·∫øt qu·∫£ th·ª±c t·∫ø c√≥ th·ªÉ kh√°c bi·ªát ƒë√°ng k·ªÉ do c√°c y·∫øu t·ªë kh√¥ng l∆∞·ªùng tr∆∞·ªõc ƒë∆∞·ª£c.</p>
                        </div>
                        """,
                        unsafe_allow_html=True
                    )
                    
                    show_popup_message(f"ƒê√£ t·∫°o d·ª± b√°o th√†nh c√¥ng cho {selected_symbol}", "success")
                else:
                    show_popup_message("Kh√¥ng th·ªÉ t·∫°o t√≥m t·∫Øt d·ª± b√°o", "warning")
    
    elif demo_option == "T·∫£i File CSV":
        st.markdown('<div class="section-header">üìÅ T·∫£i File CSV</div>', unsafe_allow_html=True)
        
        st.info("T·∫£i file CSV v·ªõi d·ªØ li·ªáu ch·ª©ng kho√°n. H·ªó tr·ª£ nhi·ªÅu ƒë·ªãnh d·∫°ng bao g·ªìm ƒë·ªãnh d·∫°ng VN30.")
        
        with st.expander("üìã C√°c ƒê·ªãnh D·∫°ng CSV ƒê∆∞·ª£c H·ªó Tr·ª£", expanded=False):
            st.write("**ƒê·ªãnh d·∫°ng 1 - ƒê·ªãnh d·∫°ng chu·∫©n:**")
            st.write("C·ªôt: date, open, high, low, close, volume, turnover")
            st.write("T√™n file: {M√É_CH·ª®NG_KHO√ÅN}_{g√¨_ƒë√≥}.csv")
            
            st.write("\n**ƒê·ªãnh d·∫°ng 2 - ƒê·ªãnh d·∫°ng VN30:**")
            st.write("C·ªôt: Date;Close;Open;High;Low;Volumn;% turnover")
            st.write("S·ª≠ d·ª•ng d·∫•u ch·∫•m ph·∫©y l√†m ph√¢n c√°ch v√† d·∫•u ph·∫©y l√†m ph√¢n c√°ch th·∫≠p ph√¢n")
            
            st.write("\n**ƒê·ªãnh d·∫°ng 3 - ƒê·ªãnh d·∫°ng qu·ªëc t·∫ø:**")
            st.write("ƒê·ªãnh d·∫°ng ph√¢n c√°ch b·∫±ng d·∫•u ph·∫©y chu·∫©n v·ªõi d·∫•u ch·∫•m l√†m ph√¢n c√°ch th·∫≠p ph√¢n")
        
        uploaded_files = st.file_uploader(
            "Ch·ªçn file CSV",
            accept_multiple_files=True,
            type=['csv'],
            help="B·∫°n c√≥ th·ªÉ t·∫£i l√™n nhi·ªÅu file CSV. H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông ph√°t hi·ªán ƒë·ªãnh d·∫°ng."
        )
        
        if uploaded_files:
            show_popup_message(f"ƒê√£ t·∫£i l√™n {len(uploaded_files)} file", "success")
            
            # Show uploaded files info
            with st.expander("üìÑ Chi Ti·∫øt File ƒê√£ T·∫£i L√™n"):
                for i, uploaded_file in enumerate(uploaded_files, 1):
                    st.write(f"{i}. **{uploaded_file.name}** ({uploaded_file.size:,} bytes)")
            
            # Save uploaded files temporarily and clean up first
            temp_dir = "/tmp/stock_data"
            
            # Clean up any existing files first
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)
            os.makedirs(temp_dir, exist_ok=True)
            
            # Save files to temp directory
            for uploaded_file in uploaded_files:
                with open(os.path.join(temp_dir, uploaded_file.name), "wb") as f:
                    f.write(uploaded_file.getbuffer())
            
            show_popup_message(f"File ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o th∆∞ m·ª•c t·∫°m: {temp_dir}", "info")
            
            # Information about next steps
            if not st.session_state.get('upload_processed', False):
                st.info("üëá **B∆∞·ªõc ti·∫øp theo:** Nh·∫•p v√†o n√∫t b√™n d∆∞·ªõi ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu v√† k√≠ch ho·∫°t t√≠nh nƒÉng d·ª± b√°o AI")
            
            # Add Process button with a unique key
            process_button = st.button(
                "üîÑ X·ª≠ L√Ω D·ªØ Li·ªáu ƒê√£ T·∫£i L√™n", 
                type="primary", 
                key="process_uploaded_data_button",
                help="Nh·∫•p ƒë·ªÉ x·ª≠ l√Ω file CSV ƒë√£ t·∫£i l√™n v√† t·∫°o ph√¢n t√≠ch"
            )
            
            if process_button:
                with st.spinner("ƒêang x·ª≠ l√Ω file CSV ƒë√£ t·∫£i l√™n..."):
                    try:
                        # Step 1: Load and process data
                        st.info("B∆∞·ªõc 1: ƒêang t·∫£i v√† x·ª≠ l√Ω file CSV...")
                        preprocessor = DataPreprocessor()
                        merged_data = preprocessor.load_and_process_all(temp_dir)
                        
                        if merged_data.empty:
                            show_popup_message("Kh√¥ng th·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu t·ª´ file ƒë√£ t·∫£i l√™n. Vui l√≤ng ki·ªÉm tra ƒë·ªãnh d·∫°ng file.", "error")
                            st.stop()
                        
                        show_popup_message(f"ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng d·ªØ li·ªáu! K√≠ch th∆∞·ªõc: {merged_data.shape}", "success")
                        st.info(f"C√°c c·ªôt c√≥ s·∫µn: {list(merged_data.columns)}")
                        
                        # Step 2: Calculate time duration
                        st.info("B∆∞·ªõc 2: ƒêang t√≠nh to√°n kho·∫£ng th·ªùi gian...")
                        uploaded_time_duration = calculate_time_duration(merged_data)
                        show_popup_message(f"Kho·∫£ng th·ªùi gian: {uploaded_time_duration}", "success")
                        
                        # Validate required columns
                        required_columns = ['close']
                        missing_columns = [col for col in required_columns if col not in merged_data.columns]
                        
                        if missing_columns:
                            show_popup_message(f"Thi·∫øu c√°c c·ªôt b·∫Øt bu·ªôc: {missing_columns}", "error")
                            st.error("File CSV c·ªßa b·∫°n ph·∫£i ch·ª©a √≠t nh·∫•t m·ªôt c·ªôt gi√° 'close'.")
                            st.stop()
                        
                        # Store in session state for persistence
                        st.session_state['upload_processed'] = True
                        st.session_state['uploaded_data'] = merged_data
                        st.session_state['uploaded_time_duration'] = uploaded_time_duration
                        
                        # Success message about AI prediction availability
                        st.success("‚úÖ **D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω th√†nh c√¥ng!** ü§ñ T√≠nh nƒÉng d·ª± b√°o AI hi·ªán ƒë√£ s·∫µn s√†ng trong thanh b√™n.")
                        
                        # Display basic info for uploaded data
                        st.markdown('<div class="section-header">üìä Ph√¢n T√≠ch D·ªØ Li·ªáu ƒê√£ T·∫£i L√™n</div>', unsafe_allow_html=True)
                        
                        try:
                            col1, col2, col3, col4, col5 = st.columns(5)
                            with col1:
                                st.metric("Th·ªùi Gian", uploaded_time_duration.split(' (')[0])
                            with col2:
                                st.metric("T·ªïng B·∫£n Ghi", len(merged_data))
                            with col3:
                                if 'close' in merged_data.columns:
                                    st.metric("Gi√° M·ªõi Nh·∫•t", f"{merged_data['close'].iloc[-1]:.2f}")
                                else:
                                    st.metric("Gi√° M·ªõi Nh·∫•t", "N/A")
                            with col4:
                                if 'return' in merged_data.columns:
                                    latest_return = merged_data['return'].iloc[-1] if not pd.isna(merged_data['return'].iloc[-1]) else 0
                                    st.metric("Thay ƒê·ªïi M·ªõi Nh·∫•t %", f"{latest_return:.2f}%")
                                else:
                                    st.metric("Thay ƒê·ªïi M·ªõi Nh·∫•t %", "N/A")
                            with col5:
                                if 'target' in merged_data.columns:
                                    up_days = (merged_data['target'] == 1).sum()
                                    st.metric("% Ng√†y TƒÉng", f"{100 * up_days / len(merged_data):.1f}%")
                                else:
                                    st.metric("% Ng√†y TƒÉng", "N/A")
                        except Exception as e:
                            st.error(f"‚ö†Ô∏è L·ªói hi·ªÉn th·ªã s·ªë li·ªáu: {str(e)}")
                        
                        # Show data preview
                        try:
                            with st.expander("üìä Ph√¢n T√≠ch D·ªØ Li·ªáu C·ªßa B·∫°n", expanded=True):
                                st.write("**Xem tr∆∞·ªõc d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω (10 d√≤ng ƒë·∫ßu):**")
                                display_data = merged_data.head(10).copy()
                                if 'date' in display_data.columns:
                                    display_data['date'] = pd.to_datetime(display_data['date']).dt.strftime('%Y-%m-%d')
                                st.dataframe(display_data, use_container_width=True)
                        except Exception as e:
                            st.error(f"‚ö†Ô∏è L·ªói hi·ªÉn th·ªã xem tr∆∞·ªõc d·ªØ li·ªáu: {str(e)}")
                        
                        # Add technical indicators
                        st.markdown('<div class="section-header">üîß Ph√¢n T√≠ch K·ªπ Thu·∫≠t</div>', unsafe_allow_html=True)
                        
                        # Validate data has required columns for technical indicators
                        required_ta_columns = ['close', 'code']
                        missing_ta_columns = [col for col in required_ta_columns if col not in merged_data.columns]
                        
                        if missing_ta_columns:
                            show_popup_message(f"Kh√¥ng th·ªÉ t√≠nh to√°n ch·ªâ b√°o k·ªπ thu·∫≠t. Thi·∫øu c·ªôt: {missing_ta_columns}", "warning")
                            st.warning("S·ª≠ d·ª•ng d·ªØ li·ªáu g·ªëc kh√¥ng c√≥ ch·ªâ b√°o k·ªπ thu·∫≠t.")
                            data_with_features = merged_data.copy()
                        else:
                            try:
                                with st.spinner("ƒêang th√™m ch·ªâ b√°o k·ªπ thu·∫≠t..."):
                                    data_with_features = add_technical_indicators(merged_data)
                                
                                show_popup_message(f"ƒê√£ th√™m ch·ªâ b√°o k·ªπ thu·∫≠t! K√≠ch th∆∞·ªõc cu·ªëi: {data_with_features.shape}", "success")
                                
                                # Debug: Show what indicators were actually added
                                with st.expander("üîç Chi Ti·∫øt Ch·ªâ B√°o K·ªπ Thu·∫≠t"):
                                    original_cols = set(merged_data.columns)
                                    new_cols = set(data_with_features.columns) - original_cols
                                    
                                    if new_cols:
                                        ma_indicators = [col for col in new_cols if 'ma_' in col.lower()]
                                        rsi_indicators = [col for col in new_cols if 'rsi' in col.lower()]
                                        bb_indicators = [col for col in new_cols if 'bb_' in col.lower()]
                                        
                                        col1, col2, col3 = st.columns(3)
                                        with col1:
                                            st.write(f"**Ch·ªâ B√°o MA:** {ma_indicators}")
                                        with col2:
                                            st.write(f"**Ch·ªâ B√°o RSI:** {rsi_indicators}")
                                        with col3:
                                            st.write(f"**D·∫£i Bollinger:** {bb_indicators}")
                                    else:
                                        st.warning("Kh√¥ng c√≥ ch·ªâ b√°o k·ªπ thu·∫≠t n√†o ƒë∆∞·ª£c t√≠nh to√°n th√†nh c√¥ng")
                            except Exception as e:
                                show_popup_message(f"L·ªói t√≠nh to√°n ch·ªâ b√°o k·ªπ thu·∫≠t: {str(e)}", "error")
                                st.warning("S·ª≠ d·ª•ng d·ªØ li·ªáu g·ªëc kh√¥ng c√≥ ch·ªâ b√°o k·ªπ thu·∫≠t.")
                                data_with_features = merged_data.copy()
                        
                        # Charts
                        st.markdown('<div class="section-header">üìà Bi·ªÉu ƒê·ªì & H√¨nh ·∫¢nh H√≥a</div>', unsafe_allow_html=True)
                        
                        # Price chart - with validation
                        try:
                            st.write("**Bi·ªÉu ƒê·ªì Gi√° v·ªõi Ch·ªâ B√°o K·ªπ Thu·∫≠t:**")
                            price_fig = plot_price_chart(data_with_features)
                            st.plotly_chart(price_fig, use_container_width=True)
                        except Exception as e:
                            st.error(f"‚ö†Ô∏è L·ªói t·∫°o bi·ªÉu ƒë·ªì gi√°: {str(e)}")
                            st.warning("B·ªè qua hi·ªÉn th·ªã bi·ªÉu ƒë·ªì gi√°.")
                        
                        # RSI chart - with validation
                        try:
                            st.write("**Ch·ªâ B√°o K·ªπ Thu·∫≠t RSI:**")
                            rsi_fig = plot_technical_indicators(data_with_features)
                            st.plotly_chart(rsi_fig, use_container_width=True)
                        except Exception as e:
                            st.error(f"‚ö†Ô∏è L·ªói t·∫°o bi·ªÉu ƒë·ªì RSI: {str(e)}")
                            st.warning("B·ªè qua hi·ªÉn th·ªã bi·ªÉu ƒë·ªì RSI.")
                        
                        # Store processed data in session state for AI prediction
                        try:
                            st.session_state['uploaded_data'] = merged_data
                            st.session_state['uploaded_features'] = data_with_features
                            st.session_state['uploaded_time_duration'] = uploaded_time_duration
                            show_popup_message("D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u trong phi√™n l√†m vi·ªác ƒë·ªÉ d·ª± b√°o AI", "success")
                        except Exception as e:
                            st.error(f"‚ö†Ô∏è L·ªói l∆∞u tr·ªØ d·ªØ li·ªáu trong phi√™n l√†m vi·ªác: {str(e)}")
                        
                        # Advanced Feature Engineering
                        st.markdown('<div class="section-header">üß† K·ªπ Thu·∫≠t X√¢y D·ª±ng ƒê·∫∑c Tr∆∞ng N√¢ng Cao</div>', unsafe_allow_html=True)
                        
                        try:
                            feature_engineer = FeatureEngineer()
                            
                            with st.spinner("ƒêang t·∫°o c√°c ƒë·∫∑c tr∆∞ng b·ªï sung..."):
                                # Add more features using the uploaded data
                                enriched_data = feature_engineer.create_price_features(data_with_features)
                                enriched_data = feature_engineer.create_volume_features(enriched_data)
                                enriched_data = feature_engineer.create_lag_features(enriched_data)
                                enriched_data = feature_engineer.create_rolling_features(enriched_data)
                            
                            col1, col2 = st.columns(2)
                            with col1:
                                st.metric("ƒê·∫∑c Tr∆∞ng G·ªëc", len(merged_data.columns))
                            with col2:
                                st.metric("ƒê·∫∑c Tr∆∞ng Cu·ªëi C√πng", len(enriched_data.columns))
                        except Exception as e:
                            st.error(f"‚ö†Ô∏è L·ªói trong k·ªπ thu·∫≠t x√¢y d·ª±ng ƒë·∫∑c tr∆∞ng: {str(e)}")
                            st.warning("S·ª≠ d·ª•ng d·ªØ li·ªáu ch·ªâ v·ªõi ch·ªâ b√°o k·ªπ thu·∫≠t.")
                            enriched_data = data_with_features.copy()
                            
                            col1, col2 = st.columns(2)
                            with col1:
                                st.metric("ƒê·∫∑c Tr∆∞ng G·ªëc", len(merged_data.columns))
                            with col2:
                                st.metric("ƒê·∫∑c Tr∆∞ng Cu·ªëi C√πng", len(enriched_data.columns))
                        
                        # Show final dataset preview
                        st.markdown('<div class="section-header">üìã Xem Tr∆∞·ªõc B·ªô D·ªØ Li·ªáu Cu·ªëi C√πng</div>', unsafe_allow_html=True)
                        
                        st.write("**Xem tr∆∞·ªõc b·ªô d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c enrich cu·ªëi c√πng (D·ªØ Li·ªáu ƒê√£ T·∫£i L√™n C·ªßa B·∫°n):**")
                        st.dataframe(enriched_data.head(), use_container_width=True)
                        
                        # Model Training Demo
                        st.markdown('<div class="section-header">ü§ñ Demo Hu·∫•n Luy·ªán M√¥ H√¨nh</div>', unsafe_allow_html=True)
                        
                        if st.button("üöÄ Ch·∫°y Demo Hu·∫•n Luy·ªán M√¥ H√¨nh", type="primary", key="model_training_uploaded"):
                            with st.spinner("ƒêang chu·∫©n b·ªã d·ªØ li·ªáu cho m√¥ h√¨nh..."):
                                # Prepare data for modeling
                                # Show data info before cleaning
                                st.info(f"üìä D·ªØ li·ªáu tr∆∞·ªõc khi l√†m s·∫°ch: {enriched_data.shape}")
                                st.info(f"üìä Gi√° tr·ªã NaN: {enriched_data.isnull().sum().sum()}")
                                
                                # Remove rows with NaN values, but be more flexible
                                clean_data = enriched_data.dropna()
                                
                                st.info(f"üìä D·ªØ li·ªáu sau khi l√†m s·∫°ch: {clean_data.shape}")
                                
                                # Lower the threshold for minimum data points
                                min_required_samples = min(10, len(enriched_data) // 4)  # More flexible threshold
                                
                                if len(clean_data) >= min_required_samples:
                                    # Split features and target
                                    feature_cols = [col for col in clean_data.columns if col not in ['code', 'target', 'date', 'year', 'month', 'day']]
                                    
                                    # Select only numeric columns for modeling
                                    numeric_features = []
                                    for col in feature_cols:
                                        if pd.api.types.is_numeric_dtype(clean_data[col]):
                                            numeric_features.append(col)
                                    
                                    X = clean_data[numeric_features]
                                    y = clean_data['target']
                                    
                                    st.info(f"üìä ƒê√£ ch·ªçn {len(numeric_features)} ƒë·∫∑c tr∆∞ng s·ªë cho m√¥ h√¨nh")
                                    
                                    # Simple train/test split
                                    split_idx = max(1, int(0.8 * len(clean_data)))  # Ensure at least 1 sample for test
                                    X_train, X_test = X[:split_idx], X[split_idx:]
                                    y_train, y_test = y[:split_idx], y[split_idx:]
                                    
                                    show_popup_message(f"D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chu·∫©n b·ªã: {len(X_train)} m·∫´u hu·∫•n luy·ªán, {len(X_test)} m·∫´u ki·ªÉm tra", "success")
                                    
                                    # Show feature importance simulation
                                    np.random.seed(42)
                                    feature_importance = np.random.rand(min(10, len(numeric_features)))
                                    top_features = np.array(numeric_features[:len(feature_importance)])
                                    
                                    importance_df = pd.DataFrame({
                                        'Feature': top_features,
                                        'Importance': feature_importance
                                    }).sort_values('Importance', ascending=True)
                                    
                                    fig_importance = px.bar(
                                        importance_df,
                                        x='Importance',
                                        y='Feature',
                                        orientation='h',
                                        title='M·ª©c ƒê·ªô Quan Tr·ªçng ƒê·∫∑c Tr∆∞ng M√¥ Ph·ªèng cho D·ªØ Li·ªáu C·ªßa B·∫°n'
                                    )
                                    st.plotly_chart(fig_importance, use_container_width=True)
                                    
                                    # Simulated model results
                                    st.write("**Hi·ªáu Su·∫•t M√¥ H√¨nh M√¥ Ph·ªèng tr√™n D·ªØ Li·ªáu C·ªßa B·∫°n:**")
                                    col1, col2, col3 = st.columns(3)
                                    with col1:
                                        st.metric("ƒê·ªô Ch√≠nh X√°c", "78.5%")
                                    with col2:
                                        st.metric("ƒê·ªô Ch√≠nh X√°c", "76.2%")
                                    with col3:
                                        st.metric("ƒê·ªô Nh·∫°y", "79.8%")
                                    
                                else:
                                    st.error(f"Kh√¥ng ƒë·ªß d·ªØ li·ªáu s·∫°ch ƒë·ªÉ m√¥ h√¨nh h√≥a. C·∫ßn √≠t nh·∫•t {min_required_samples} m·∫´u, nh∆∞ng ch·ªâ c√≥ {len(clean_data)} sau khi l√†m s·∫°ch.")
                                    st.error("H√£y th·ª≠ t·∫£i l√™n nhi·ªÅu d·ªØ li·ªáu h∆°n ho·∫∑c ki·ªÉm tra ch·∫•t l∆∞·ª£ng d·ªØ li·ªáu.")
                        
                    except Exception as e:
                        st.error(f"L·ªói x·ª≠ l√Ω file: {str(e)}")
        
        # AI Prediction for uploaded data - moved outside process_button block
        if uploaded_files and st.session_state.get('upload_processed', False):
            st.markdown('<div class="section-header">ü§ñ Ph√¢n T√≠ch AI cho D·ªØ Li·ªáu C·ªßa B·∫°n</div>', unsafe_allow_html=True)
            
            # Check if sidebar AI prediction button was pressed and we have uploaded data
            if use_ai_prediction and st.session_state.get('upload_processed', False):
                with st.spinner("AI ƒëang ph√¢n t√≠ch d·ªØ li·ªáu th·ªã tr∆∞·ªùng c·ªßa b·∫°n..."):
                    try:
                        # Validate that we have the required data
                        if 'uploaded_data' not in st.session_state or st.session_state['uploaded_data'].empty:
                            show_popup_message("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ƒë√£ t·∫£i l√™n. Vui l√≤ng x·ª≠ l√Ω d·ªØ li·ªáu c·ªßa b·∫°n tr∆∞·ªõc.", "error")
                            st.stop()
                        
                        # Get processed data from session state
                        processed_data = st.session_state['uploaded_data']
                        
                        # Validate required columns
                        required_columns = ['close']
                        missing_columns = [col for col in required_columns if col not in processed_data.columns]
                        
                        if missing_columns:
                            show_popup_message(f"Thi·∫øu c√°c c·ªôt b·∫Øt bu·ªôc: {missing_columns}", "error")
                            st.error("Vui l√≤ng ƒë·∫£m b·∫£o file CSV c·ªßa b·∫°n ch·ª©a √≠t nh·∫•t m·ªôt c·ªôt gi√° 'close'.")
                            st.stop()
                        
                        # Calculate latest return safely
                        if 'return' in processed_data.columns and len(processed_data) > 1:
                            latest_return = processed_data['return'].iloc[-1] if not pd.isna(processed_data['return'].iloc[-1]) else 0
                        else:
                            # Calculate manually if return column doesn't exist
                            if len(processed_data) >= 2:
                                latest_close = processed_data['close'].iloc[-1]
                                prev_close = processed_data['close'].iloc[-2]
                                latest_return = ((latest_close - prev_close) / prev_close) * 100
                            else:
                                latest_return = 0
                        
                        # Get time duration
                        uploaded_time_duration = st.session_state.get('uploaded_time_duration', 'Unknown duration')
                        
                        # Prepare data summary for uploaded data with safe access
                        uploaded_summary = {
                            'total_days': len(processed_data),
                            'time_duration': uploaded_time_duration,
                            'current_price': processed_data['close'].iloc[-1] if len(processed_data) > 0 else 0,
                            'latest_change': latest_return,
                            'up_days_ratio': 100 * (processed_data['target'] == 1).sum() / len(processed_data) if 'target' in processed_data.columns and len(processed_data) > 0 else 50,
                            'highest_price': processed_data['close'].max() if len(processed_data) > 0 else 0,
                            'lowest_price': processed_data['close'].min() if len(processed_data) > 0 else 0,
                            'avg_volatility': abs(processed_data['return']).mean() if 'return' in processed_data.columns and len(processed_data) > 0 else 0
                        }
                        
                        # Use hardcoded API key
                        api_key = "AIzaSyDMs-iLWgB7NuoCtJLqEj4SwG3qhM3B-gQ"
                        
                        # Get AI prediction for uploaded data
                        ai_prediction_uploaded = get_gemini_prediction(uploaded_summary, api_key)
                        
                        # Display prediction with enhanced UI
                        st.markdown("---")
                        st.markdown("### üîÆ Ph√¢n T√≠ch AI D·ªØ Li·ªáu Th·ªã Tr∆∞·ªùng C·ªßa B·∫°n")
                        
                        if "L·ªói" not in ai_prediction_uploaded:
                            # Create an enhanced display for uploaded data analysis
                            with st.container():
                                show_popup_message("Ph√¢n t√≠ch d·ªØ li·ªáu c·ªßa b·∫°n ho√†n t·∫•t!", "success")
                                
                                # Show key metrics in columns
                                col1, col2, col3, col4 = st.columns(4)
                                with col1:
                                    st.metric("ƒêi·ªÉm D·ªØ Li·ªáu", f"{uploaded_summary['total_days']:,}")
                                with col2:
                                    if uploaded_summary['current_price'] > 0:
                                        st.metric("Gi√° Hi·ªán T·∫°i", f"{uploaded_summary['current_price']:.2f}")
                                with col3:
                                    st.metric("Thay ƒê·ªïi M·ªõi Nh·∫•t", f"{uploaded_summary['latest_change']:.2f}%")
                                with col4:
                                    st.metric("T·ª∑ L·ªá Ng√†y TƒÉng", f"{uploaded_summary['up_days_ratio']:.1f}%")
                                
                                st.markdown("---")
                                
                                # Display the AI prediction in a styled container with black background
                                st.markdown("#### üìä Ph√¢n T√≠ch Chi Ti·∫øt D·ªØ Li·ªáu C·ªßa B·∫°n:")
                                
                                # Create a styled container for the prediction (same as sample demo)
                                prediction_container = st.container()
                                with prediction_container:
                                    formatted_response = format_gemini_response(ai_prediction_uploaded)
                                    st.markdown(
                                        f"""
                                        <div style='background-color: #000000; color: #ffffff; padding: 20px; border-radius: 10px; border-left: 5px solid #1f77b4; margin: 10px 0;'>
                                            {formatted_response}
                                        </div>
                                        """,
                                        unsafe_allow_html=True
                                    )
                                
                                # Add future prediction for uploaded data
                                st.markdown("#### üîÆ D·ª± B√°o M·ªü R·ªông (10 NƒÉm Ti·∫øp Theo)")
                                future_prediction_uploaded = generate_future_prediction(uploaded_summary)
                                st.info(future_prediction_uploaded)
                                
                                # Add disclaimer with prominent styling
                                st.markdown("---")
                                st.warning(
                                    "‚ö†Ô∏è **L∆ØU √ù QUAN TR·ªåNG:** ƒê√¢y l√† ph√¢n t√≠ch AI d·ª±a tr√™n d·ªØ li·ªáu l·ªãch s·ª≠ c·ªßa b·∫°n. "
                                    "Kh√¥ng ƒë∆∞·ª£c coi l√† l·ªùi khuy√™n ƒë·∫ßu t∆∞. Th·ªã tr∆∞·ªùng ch·ª©ng kho√°n c√≥ r·ªßi ro cao. "
                                    "Vui l√≤ng tham kh·∫£o √Ω ki·∫øn chuy√™n gia t√†i ch√≠nh tr∆∞·ªõc khi ƒë∆∞a ra quy·∫øt ƒë·ªãnh ƒë·∫ßu t∆∞."
                                )
                        else:
                            st.error(ai_prediction_uploaded)
                    
                    except Exception as e:
                        st.error(f"L·ªói x·ª≠ l√Ω d·ªØ li·ªáu ƒë√£ t·∫£i l√™n cho d·ª± b√°o AI: {str(e)}")
                        st.error("Vui l√≤ng ƒë·∫£m b·∫£o d·ªØ li·ªáu c·ªßa b·∫°n ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω th√†nh c√¥ng tr∆∞·ªõc khi y√™u c·∫ßu d·ª± b√°o AI.")
            
            # Info message when no AI prediction button is pressed yet
            else:
                st.info("üí° Nh·∫•p v√†o n√∫t 'Nh·∫≠n D·ª± B√°o Th·ªã Tr∆∞·ªùng AI' trong thanh b√™n ƒë·ªÉ ph√¢n t√≠ch d·ªØ li·ªáu ƒë√£ t·∫£i l√™n v·ªõi AI")
        
        # If no files uploaded yet, show info
        else:
            st.info("üìÅ Vui l√≤ng t·∫£i l√™n file CSV ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch")
    
    # Footer
    st.markdown("---")
    st.markdown(
        """
        <div style="text-align: center; color: #666;">
            <p>üìä H·ªá Th·ªëng D·ª± B√°o Th·ªã Tr∆∞·ªùng Ch·ª©ng Kho√°n</p>
            <p>ƒê∆∞·ª£c ph√°t tri·ªÉn v·ªõi Machine Learning v√† AI</p>
        </div>
        """,
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()
